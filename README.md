# ğŸš€ Titier

**O Titier Ã© um assistente de estudos impulsionado por IA que funciona de forma 100% local e privada.** Ele transforma seus PDFs em conhecimento acessÃ­vel, permitindo que vocÃª converse com seus documentos usando InteligÃªncia Artificial rodando 100% no seu computador.

## ğŸš€ Como Obter o Titier

### OpÃ§Ã£o 1: Download do ExecutÃ¡vel (Recomendado)
VocÃª pode baixar as versÃµes mais recentes prontas para uso na pÃ¡gina de **[Releases do GitHub](https://github.com/matheusdanoite/Titier/releases)**. Temos instaladores para:
- **Windows**: `.exe` (Suporta NVIDIA CUDA)
- **macOS**: `.dmg` (Nativo para Apple Silicon)

### OpÃ§Ã£o 2: CompilaÃ§Ã£o Manual
Se vocÃª deseja compilar o projeto do zero, siga as instruÃ§Ãµes abaixo:

## ğŸ›  PrÃ©-requisitos

![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-warning)
![License](https://img.shields.io/badge/License-MIT-blue)
![Python](https://img.shields.io/badge/Python-3.11-blue)
![Tauri](https://img.shields.io/badge/Tauri-2.0-orange)
![React](https://img.shields.io/badge/React-19-blue)

## âœ¨ Funcionalidades

- **ğŸ”’ 100% Local (Privacidade Total):** Seus documentos e conversas nunca saem do seu computador.
- **ğŸ§  IA Multimodal:** Entende texto, tabelas, grÃ¡ficos e anotaÃ§Ãµes manuscritas.
- **ğŸ“š RAG (Retrieval-Augmented Generation):** Respostas baseadas fielmente no conteÃºdo dos seus PDFs.
- **ğŸ’¬ Chat Multi-SessÃ£o:** Gerencie mÃºltiplas conversas simultÃ¢neas com contextos independentes.
- **âš¡ Streaming em Tempo Real:** Respostas exibidas token a token para feedback instantÃ¢neo.
- **ğŸš€ Performance Nativa:** Backend em Python otimizado (Metal/CUDA) + Frontend leve em Rust/Tauri.

---

## ğŸ› ï¸ Tecnologias

- **Backend:** Python 3.11, FastAPI, LlamaIndex, Qdrant (Vetores), PyMuPDF.
- **AI Engine:** `llama-cpp-python` para visÃ£o e linguagem, `rapidocr-onnxruntime` para OCR.
- **Frontend:** Tauri v2, React, TypeScript, Vite, TailwindCSS.

---

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

1.  **Node.js** (v18 ou superior)
2.  **Python** (v3.11 recomendado)
3.  **Rust** (Latest stable)
4.  **Poetry** (Gerenciador de dependÃªncias Python)
    ```bash
    pip install poetry
    ```
5.  **Compiladores C++:**
    - **macOS:** Xcode Command Line Tools (`xcode-select --install`)
    - **Windows:** Visual Studio com "Desktop development with C++"

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o (Desenvolvimento)

Siga os passos abaixo para rodar o projeto localmente.

### 1. Backend (Python)

ConfiguraÃ§Ã£o do servidor de IA e API.

```bash
# 1. Navegue atÃ© a pasta do projeto
cd titier

# 2. Instale as dependÃªncias com Poetry
poetry install

# 3. Configure a aceleraÃ§Ã£o de hardware (Metal/CUDA)
# Este script recompila o llama-cpp-python para sua GPU especÃ­fica
chmod +x app/install.sh
./app/install.sh
```

**Modelos de IA:**
O sistema precisa de modelos GGUF para funcionar.
1.  Crie a pasta: `mkdir -p ~/.titier/models`
2.  Baixe modelos (ex: Llama-3.1-8B-Instruct-Q4_K_M.gguf) e coloque nesta pasta.
3.  O `server.py` buscarÃ¡ modelos automaticamente neste diretÃ³rio e utilizarÃ¡ uma **janela de contexto otimizada de 8192 tokens** para garantir estabilidade e performance em hardware local.

**Rodar o Backend:**
```bash
poetry run python -m app.server
# O servidor iniciarÃ¡ em http://127.0.0.1:8000
```

### 2. Frontend (Tauri/React)

Interface grÃ¡fica do usuÃ¡rio.

```bash
# 1. Navegue para a pasta frontend
cd frontend

# 2. Instale as dependÃªncias
npm install

# 3. Inicie o modo de desenvolvimento
npm run tauri dev
```

O aplicativo abrirÃ¡ em uma janela nativa.

---

## ğŸ“¦ Build para ProduÃ§Ã£o

Para gerar o executÃ¡vel final (`.app` ou `.exe`).

### 1. Compilar o Backend (Sidecar)

O Tauri precisa de um executÃ¡vel do Python para empacotar junto. Usamos o PyInstaller.

```bash
# Na raiz do projeto
poetry run pyinstaller app/server.py \
  --name titier-backend \
  --onefile \
  --collect-all llama_cpp \
  --collect-all sentence_transformers \
  --collect-all qdrant_client
```

*Nota: Mova o executÃ¡vel gerado em `dist/titier-backend` para `frontend/src-tauri/sidecars/` renomeando-o conforme a arquitetura (ex: `titier-backend-aarch64-apple-darwin`).*

### 2. Compilar o App Tauri

```bash
cd frontend
npm run tauri build
```

O instalador estarÃ¡ em `frontend/src-tauri/target/release/bundle`.

---

## ğŸ“‚ Estrutura do Projeto

```
Titier/
â”œâ”€â”€ app/                 # Backend Python (FastAPI + IA)
â”‚   â”œâ”€â”€ core/            # LÃ³gica de IA (InferÃªncia, Agente)
â”‚   â”œâ”€â”€ db/              # Banco de Vetores (Qdrant)
â”‚   â”œâ”€â”€ server.py        # Entry point da API
â”‚   â””â”€â”€ install.sh       # Script de setup de ambiente
â”œâ”€â”€ frontend/            # Frontend (Tauri + React)
â”‚   â”œâ”€â”€ src/             # CÃ³digo React
â”‚   â””â”€â”€ src-tauri/       # ConfiguraÃ§Ã£o Rust/Tauri
â”œâ”€â”€ poetry.lock          # DependÃªncias Python travadas
â””â”€â”€ pyproject.toml       # ConfiguraÃ§Ã£o do projeto Python
```

## ğŸ¤ ContribuiÃ§Ã£o

1.  FaÃ§a um Fork do projeto
2.  Crie uma Branch para sua Feature (`git checkout -b feature/metamorfose`)
3.  Commit suas mudanÃ§as (`git commit -m 'Uma metamorfose ambulante'`)
4.  Push para a Branch (`git push origin feature/metamorfose`)
5.  Abra um Pull Request